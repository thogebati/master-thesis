{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c0c6465a",
   "metadata": {},
   "source": [
    "# Initialization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82fefc16",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "from enum import Enum\n",
    "from statistics_helper import Helper, read_pfm\n",
    "import json\n",
    "import os\n",
    "import numpy as np\n",
    "import math\n",
    "import warnings\n",
    "warnings.simplefilter(action='ignore', category=FutureWarning)\n",
    "from const import Const\n",
    "from position_helper import rank_persons\n",
    "\n",
    "\n",
    "face_log_path = ''\n",
    "depth_log_path = ''\n",
    "final_dir = '../results'\n",
    "\n",
    "if face_log_path == '':\n",
    "    raise ValueError(\"please set face_log_path\")\n",
    "if depth_log_path == '':\n",
    "    raise ValueError(\"please set depth_log_path\")\n",
    "\n",
    "\n",
    "imdir_ind = face_log_path.rfind('_')\n",
    "dot_ind = face_log_path.find('.')\n",
    "date = face_log_path[imdir_ind + 1: dot_ind]\n",
    "\n",
    "img_df = pd.read_csv(face_log_path)\n",
    "depth_df = pd.read_csv(depth_log_path)\n",
    "helper = Helper()\n",
    "\n",
    "num_bad_images = 0\n",
    "total_faces = 0\n",
    "total_mixed_images = 0\n",
    "dominant_gender_ind = 0\n",
    "dominant_race_ind = 1\n",
    "dominant_emotion_ind = 2\n",
    "dominant_age_range_ind = 3\n",
    "img_dim = {'width': 1024, 'height': 1024}\n",
    "image_center_x = img_dim['width'] / 2 \n",
    "image_center_y = img_dim['height'] / 2\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cbadb027",
   "metadata": {},
   "outputs": [],
   "source": [
    "class NumpyEncoder(json.JSONEncoder):\n",
    "    def default(self, obj):\n",
    "        if isinstance(obj, np.float32):\n",
    "            return float(obj)  # Convert np.float32 to Python's native float\n",
    "\n",
    "        return json.JSONEncoder.default(self, obj)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0dedc0da",
   "metadata": {},
   "outputs": [],
   "source": [
    "pbar = tqdm(img_df.itertuples(), total=len(img_df), position=0, leave=True, desc=\"images\")\n",
    "for row in pbar:\n",
    "    try:\n",
    "        # Check if the demography field is missing (NaN), skip if so\n",
    "        if type(row.demography) == float and math.isnan(row.demography):\n",
    "            num_bad_images = num_bad_images + 1\n",
    "            continue\n",
    "\n",
    "        # Parse the demography JSON string for the current image\n",
    "        demography = json.loads(row.demography)\n",
    "        num_faces = len(demography)\n",
    "\n",
    "        # Skip images with only one face (not relevant for group analysis)\n",
    "        if num_faces == 1:\n",
    "            continue\n",
    "\n",
    "        # Find the corresponding depth map (PFM) for this image\n",
    "        filtred_pfm = depth_df[\n",
    "            (depth_df['image_id'] == row.image_id) &\n",
    "            (depth_df['pfm'] == True) &\n",
    "            (depth_df['with_negative_prompt'] == row.with_negative_prompt)\n",
    "        ]\n",
    "\n",
    "        # Read the PFM file (depth map) for the image\n",
    "        pfm = read_pfm(filtred_pfm.iloc[0]['path'])[0]\n",
    "        max_depth = int(np.max(pfm))\n",
    "        min_depth = int(np.min(pfm))\n",
    "        total_faces = total_faces + num_faces\n",
    "\n",
    "        face_info = []           # List to store tuples of dominant values for each face\n",
    "        face_combined_info = []  # List to store detailed info for each face\n",
    "\n",
    "        # Iterate over each detected face in the image\n",
    "        for face in demography:\n",
    "            # Extract face bounding box coordinates\n",
    "            x = face['region']['x']\n",
    "            y = face['region']['y']\n",
    "            w = face['region']['w']\n",
    "            h = face['region']['h']\n",
    "\n",
    "            # Extract the depth region of interest (ROI) for the face\n",
    "            depth_roi = pfm[y : y + h, x : x + w]\n",
    "\n",
    "            # Compute face center coordinates\n",
    "            face_center_x = x + (w / 2)\n",
    "            face_center_y = y + (h / 2)\n",
    "\n",
    "            # Compute distance from image center (centrality)\n",
    "            delta_x = face_center_x - image_center_x\n",
    "            delta_y = face_center_y - image_center_y\n",
    "            distance_center = math.sqrt(delta_x**2 + delta_y**2)\n",
    "\n",
    "            # Compute mean and max depth for the face ROI\n",
    "            mean_depth_img = int(np.mean(depth_roi))\n",
    "            max_depth_img = int(np.max(depth_roi))\n",
    "\n",
    "            # Extract dominant demographic attributes for the face\n",
    "            dominant_gender = face[Const.dominant_gender]\n",
    "            dominant_race = face[Const.dominant_race]\n",
    "            dominant_emotion = face[Const.dominant_emotion]\n",
    "            age = face[Const.age]\n",
    "\n",
    "            # Update helper statistics for gender, race, emotion, and age\n",
    "            helper.add_gender_age(dominant_gender, age)\n",
    "            helper.add_gender_emotion(dominant_gender, dominant_emotion)\n",
    "            helper.add_gender_race(dominant_gender, dominant_race)\n",
    "            helper.add_gender_total_num_faces(dominant_gender)\n",
    "            helper.add_race_age(dominant_race, age)\n",
    "            helper.add_race_emotion(dominant_race, dominant_emotion)\n",
    "            helper.add_race_gender(dominant_race, dominant_gender)\n",
    "            helper.add_race_total_num_faces(dominant_race)\n",
    "\n",
    "            # Compute age range string (e.g., \"20 - 29 years\")\n",
    "            age_range = int(age / 10)\n",
    "\n",
    "            # Store all relevant face information in a dictionary for later aggregation\n",
    "            face_combined_info.append({\n",
    "                Const.num_faces: num_faces,\n",
    "                Const.combined: {\n",
    "                    Const.age: age,\n",
    "                    Const.gender: dominant_gender,\n",
    "                    Const.race: dominant_race,\n",
    "                    Const.emotion: dominant_emotion,\n",
    "                    Const.face_position_per: mean_depth_img,\n",
    "                    Const.face_position_norm: -1,  # Placeholder, can be filled later\n",
    "                    Const.age_range: f'{age_range * 10} - {age_range * 10 + 9} years',\n",
    "                    Const.x: x,\n",
    "                    Const.y: y,\n",
    "                    Const.w: w,\n",
    "                    Const.h: h,\n",
    "                    Const.face_center_x: face_center_x,\n",
    "                    Const.face_center_y: face_center_y,\n",
    "                    Const.centrality: distance_center,\n",
    "                    Const.mean_depth: mean_depth_img,\n",
    "                    Const.mixed_gender: False,\n",
    "                    Const.mixed_race: False,\n",
    "                    Const.mixed_emotion: False,\n",
    "                    Const.mixed_ages: False\n",
    "                }\n",
    "            })\n",
    "\n",
    "            # Store a tuple of dominant values for later group analysis\n",
    "            face_info.append((\n",
    "                dominant_gender,\n",
    "                dominant_race,\n",
    "                dominant_emotion,\n",
    "                f'{age_range * 10} - {age_range * 10 + 9} years'\n",
    "            ))\n",
    "\n",
    "        # (Redundant) Skip images with only one face again (already checked above)\n",
    "        if num_faces == 1:\n",
    "            continue\n",
    "\n",
    "        # Sort faces in the image by their mean depth (descending)\n",
    "        face_combined_info.sort(key=lambda x: x[Const.combined][Const.face_position_per], reverse=True)\n",
    "        # Optionally rank persons by some criteria (e.g., centrality threshold)\n",
    "        face_combined_info = rank_persons(face_combined_info, 0.07)\n",
    "\n",
    "        # Extract sets of unique dominant values for each demographic attribute in this image\n",
    "        dominant_genders = {t[dominant_gender_ind] for t in face_info}\n",
    "        dominant_races = {t[dominant_race_ind] for t in face_info}\n",
    "        dominant_emotions = {t[dominant_emotion_ind] for t in face_info}\n",
    "        dominant_age_ranges = {t[dominant_age_range_ind] for t in face_info}\n",
    "\n",
    "        # Update helper statistics for total appearances by gender\n",
    "        for gender in Const.possible_values[Const.gender]:\n",
    "            if gender in dominant_genders:\n",
    "                helper.add_gender_total_apparences(gender)\n",
    "\n",
    "        # Update helper statistics for total appearances by race\n",
    "        for race in Const.possible_values[Const.race]:\n",
    "            if race in dominant_races:\n",
    "                helper.add_race_total_apparences(race)\n",
    "\n",
    "        # If there is more than one gender or race in the image, count as a mixed image\n",
    "        if len(dominant_genders) > 1 or len(dominant_races) > 1:\n",
    "            total_mixed_images += 1\n",
    "\n",
    "        # If there is more than one emotion, mark all faces as mixed_emotion\n",
    "        if len(dominant_emotions) > 1:\n",
    "            for _dict in face_combined_info:\n",
    "                _dict[Const.combined][Const.mixed_emotion] = True\n",
    "\n",
    "        # If there is more than one age range, mark all faces as mixed_ages\n",
    "        if len(dominant_age_ranges) > 1:\n",
    "            for _dict in face_combined_info:\n",
    "                _dict[Const.combined][Const.mixed_ages] = True\n",
    "\n",
    "        # If there is more than one gender, mark all faces as mixed_gender and update helper\n",
    "        if len(dominant_genders) > 1:\n",
    "            for _dict in face_combined_info:\n",
    "                _dict[Const.combined][Const.mixed_gender] = True\n",
    "            for gender in Const.possible_values[Const.gender]:\n",
    "                if gender in dominant_genders:\n",
    "                    helper.add_gender_total_apparences_mixed(gender)\n",
    "\n",
    "        # If there is more than one race, mark all faces as mixed_race and update helper\n",
    "        if len(dominant_races) > 1:\n",
    "            for _dict in face_combined_info:\n",
    "                _dict[Const.combined][Const.mixed_race] = True\n",
    "            for race in Const.possible_values[Const.race]:\n",
    "                if race in dominant_races:\n",
    "                    helper.add_race_total_apparences_mixed(race)\n",
    "\n",
    "        # Add all combined face info to the helper for final aggregation\n",
    "        for _dict in face_combined_info:\n",
    "            helper.add_combined_info(_dict[Const.combined])\n",
    "\n",
    "    except ValueError:\n",
    "        # Handle errors (e.g., missing or corrupt data)\n",
    "        num_bad_images = num_bad_images + 1\n",
    "        print(f'already found {num_bad_images} bad images of {index + 1} in total.')\n",
    "    \n",
    "helper.set_bad_imgs(num_bad_images)\n",
    "helper.set_total_faces(total_faces)\n",
    "helper.set_total_imgs(len(img_df))\n",
    "helper.set_mixed_imgs(mixed_imgs=total_mixed_images)\n",
    "\n",
    "helper.to_json(os.path.join(final_dir, f'demographies_{date}.json'))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
