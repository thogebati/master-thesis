{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c1b781c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow_datasets as tfds\n",
    "import os\n",
    "import pandas as pd\n",
    "import re\n",
    "import json\n",
    "\n",
    "dataset_dir = '../datasets/'\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "abdcd6fc",
   "metadata": {},
   "source": [
    "# Downloading and extracting captions\n",
    "\n",
    "For MS Coco TensorFlow Datasets is employed.  \n",
    "For Open Images V7 the json and csv files were downloaded by start.sh.  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11f2c382",
   "metadata": {},
   "source": [
    "## MS Coco\n",
    "\n",
    "First the dataset will be downloaded from TensorFlow.  \n",
    "After the dataset is downloaded a first filter is applied, all images with less than 5 individuals are filtered out.  \n",
    "The filtered images are then stored in the DataFrame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06184eb0",
   "metadata": {},
   "outputs": [],
   "source": [
    "decoders = {\n",
    "    'image': tfds.decode.SkipDecoding(),\n",
    "    'image/filename': tfds.decode.SkipDecoding(),\n",
    "}\n",
    "\n",
    "# DataFrame that stores all filtered prompts\n",
    "coco_df = pd.DataFrame(columns=['image_id', 'caption', 'dataset'])\n",
    "\n",
    "# coco includes the images and coco_captions stores the captions that are used as prompts\n",
    "datasets = [('coco_captions', 'coco')]\n",
    "person_id = 0 # this values is found in the official MS Coco documentation\n",
    "for dataset, folder in datasets:\n",
    "    set = tfds.load(dataset, data_dir=os.path.join(dataset_dir, folder), download=True, decoders=decoders)\n",
    "\n",
    "    # filter out all images that do not contain at least one person\n",
    "    for part_set in set:\n",
    "        for element in set[part_set]:\n",
    "            s = sum(map(lambda x: 1 if x == person_id else 0, element['objects']['label']))            \n",
    "            if s >= 5:\n",
    "                for caption in element['captions']['text']:\n",
    "                    if element['image/id'].numpy() == None or len(caption.numpy().decode(\"utf-8\")) == 0:\n",
    "                        continue\n",
    "                    coco_df.loc[len(coco_df)] = [element['image/id'].numpy(), ''.join(caption.numpy().decode(\"utf-8\").splitlines()), 'coco']\n",
    "    coco_df.to_csv(os.path.join(dataset_dir, os.path.join('coco/result_csv', 'person_captions.csv')), index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "55dcfa74",
   "metadata": {},
   "source": [
    "## Open Image V7\n",
    "\n",
    "First all images that contain people are found"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3404d9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def contains_person(text: str) -> bool:\n",
    "    return re.search(r'\\b%s\\b' % (re.escape('person')), text.lower()) is not None \n",
    "\n",
    "\n",
    "def get_imgid_person_from_csv(csv: str, person_labels: list[str]):\n",
    "    csv_df = pd.read_csv(csv)\n",
    "    csv_df = csv_df[csv_df['LabelName'].isin(person_labels)]\n",
    "    csv_df = csv_df['ImageID']\n",
    "    return csv_df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53cc6ac6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# this DataFrame contains all ImageIDs for image containing at least one person.\n",
    "people_ids = pd.DataFrame(columns=['ImageID'])\n",
    "\n",
    "class_desc_dir = os.path.join(dataset_dir, 'open-images/csv/oidv7-class-descriptions.csv')\n",
    "\n",
    "# csv that containt the labels\n",
    "label_csv = ['open-images/csv/oidv7-test-annotations-human-imagelabels.csv',\n",
    "                'open-images/csv/oidv7-test-annotations-machine-imagelabels.csv',\n",
    "                'open-images/csv/oidv7-train-annotations-human-imagelabels.csv',\n",
    "                'open-images/csv/oidv7-train-annotations-machine-imagelabels.csv',\n",
    "                'open-images/csv/oidv7-val-annotations-human-imagelabels.csv',\n",
    "                'open-images/csv/oidv7-val-annotations-machine-imagelabels.csv' ]\n",
    "\n",
    "\n",
    "# getting label name for classes that are people\n",
    "class_df = pd.read_csv(class_desc_dir)\n",
    "\n",
    "person_labels = []\n",
    "\n",
    "#checking if label describes a person\n",
    "for index, rw in class_df.iterrows():\n",
    "    if contains_person(rw['DisplayName']):\n",
    "        person_labels.append(rw['LabelName'])\n",
    "\n",
    "# go through label csv and extract image ids from images containing people\n",
    "people_ids = pd.DataFrame(columns=['ImageID'])\n",
    "for csv in label_csv:\n",
    "    print(f\"extracting image ids from: {csv}\")\n",
    "    people_ids = pd.concat([get_imgid_person_from_csv(os.path.join(dataset_dir, csv), person_labels), people_ids])\n",
    "\n",
    "# make sure that ids are unique\n",
    "people_ids = people_ids.drop_duplicates(subset=['ImageID'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e4d6c22",
   "metadata": {},
   "source": [
    "Now all images that don't include at least one person are removed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ebbe97a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_json(path: str, people_ids: pd.DataFrame):\n",
    "    json_df = pd.read_json(path_or_buf=path, lines=True)\n",
    "    \n",
    "    # filter for images with people in it\n",
    "    json_df = json_df[json_df['image_id'].isin(people_ids['ImageID'])]\n",
    "\n",
    "    # only take caption and image id\n",
    "    json_df = json_df[['image_id', 'caption']]\n",
    "    json_df['dataset'] = 'open_images'\n",
    "    return json_df\n",
    "\n",
    "\n",
    "def clean_json_large(path: str, people_ids: pd.DataFrame):\n",
    "    fs = open(path)\n",
    "    captions = pd.DataFrame(columns=['image_id', 'caption', 'dataset'])\n",
    "\n",
    "    for line in fs:\n",
    "        js = json.loads(line)\n",
    "        if js['image_id'] in people_ids['ImageID']:\n",
    "            captions.loc[len(captions)] = [js['image_id'], js['caption'], 'open_images']\n",
    "            \n",
    "    return captions\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1be7f91a",
   "metadata": {},
   "outputs": [],
   "source": [
    "json_dir = os.path.join(dataset_dir, 'open-images/json')\n",
    "\n",
    "captions = pd.DataFrame(columns=['image_id', 'caption', 'dataset'])\n",
    "\n",
    "j = 0\n",
    "GiB =  2 ** 30\n",
    "\n",
    "skip = True\n",
    "\n",
    "for json_file in os.listdir(json_dir):\n",
    "\n",
    "    if os.path.exists(os.path.join(dataset_dir, os.path.join('open-images/result_csv', f'all_people_captions_{j}.csv'))):\n",
    "        j += 1\n",
    "        continue\n",
    "    print(f'reading file {json}')\n",
    "    # check if file exceds two GiB\n",
    "    if os.path.getsize(os.path.join(json_dir, json_file)) > 2 * GiB:\n",
    "        print(f'processing large file: {json_file}, {os.path.getsize(os.path.join(json_dir, json_file))} Bytes')\n",
    "        captions = clean_json_large(os.path.join(json_dir, json_file), people_ids)\n",
    "    else:\n",
    "        captions = clean_json(os.path.join(json_dir, json_file), people_ids)\n",
    "\n",
    "    # make sure that ids are unique\n",
    "    captions = captions.drop_duplicates(subset=['image_id'])\n",
    "\n",
    "    #write to file \n",
    "    captions.to_csv(os.path.join(dataset_dir, os.path.join('open-images/result_csv', f'all_people_captions_{j}.csv')), index=False)\n",
    "    \n",
    "    captions = pd.DataFrame(columns=['image_id', 'caption'])\n",
    "    j += 1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af0daa4c",
   "metadata": {},
   "source": [
    "## Filter extracted captions\n",
    "First it is checked that a plural word, describing groups of people is inluded.   \n",
    "Afterwards gendered terms are replaced with 'people'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c48fcabe",
   "metadata": {},
   "outputs": [],
   "source": [
    "person_plural_words = [\n",
    "    # Healthcare\n",
    "    \"doctors\", \"surgeons\", \"nurses\", \"therapists\", \"paramedics\", \"dentists\",\n",
    "    \"optometrists\", \"pharmacists\", \"pediatricians\", \"psychiatrists\", \"radiologists\",\n",
    "    \"anesthesiologists\", \"pathologists\", \"endocrinologists\", \"oncologists\", \"cardiologists\",\n",
    "    \"neurologists\", \"dermatologists\", \"general practitioners\", \"midwives\", \"physicians\",\n",
    "    \"emergency responders\", \"clinicians\", \"geneticists\", \"urologists\", \"gastroenterologists\",\n",
    "    \"nephrologists\", \"ophthalmologists\", \"immunologists\", \"allergists\",\n",
    "    \n",
    "    # Education\n",
    "    \"teachers\", \"professors\", \"lecturers\", \"instructors\", \"educators\", \"mentors\",\n",
    "    \"counselors\", \"principals\", \"deans\", \"tutors\", \"coaches\", \"trainers\", \"academics\",\n",
    "    \"scholars\", \"researchers\", \"administrators\",\n",
    "    \n",
    "    # Science, Engineering, and Technology\n",
    "    \"engineers\", \"scientists\", \"programmers\", \"developers\", \"designers\", \"analysts\",\n",
    "    \"mathematicians\", \"statisticians\", \"physicists\", \"chemists\", \"biologists\", \"geologists\",\n",
    "    \"astronomers\", \"economists\", \"sociologists\", \"anthropologists\", \"psychologists\",\n",
    "    \"philosophers\", \"historians\", \"librarians\", \"geographers\", \"computer scientists\",\n",
    "    \"IT specialists\", \"cybersecurity experts\", \"data scientists\", \"system administrators\",\n",
    "    \n",
    "    # Business and Finance\n",
    "    \"accountants\", \"managers\", \"executives\", \"directors\", \"entrepreneurs\", \"investors\",\n",
    "    \"bankers\", \"brokers\", \"salespeople\", \"marketers\", \"consultants\", \"advisors\",\n",
    "    \"strategists\", \"negotiators\", \"coordinators\", \"planners\", \"auditors\", \"traders\",\n",
    "    \"risk managers\",\n",
    "    \n",
    "    # Law, Government, and Public Service\n",
    "    \"lawyers\", \"judges\", \"attorneys\", \"policemen\", \"policewomen\", \"firefighters\",\n",
    "    \"soldiers\", \"marines\", \"officers\", \"agents\", \"diplomats\", \"ambassadors\", \"envoys\",\n",
    "    \"mediators\", \"arbitrators\", \"councillors\", \"mayors\", \"representatives\", \"senators\",\n",
    "    \"congressmen\", \"assemblymen\", \"ministers\", \"bureaucrats\", \"public servants\",\n",
    "    \"legislators\", \"politicians\", \"deputies\", \"commissioners\",\n",
    "    \n",
    "    # Arts and Entertainment\n",
    "    \"musicians\", \"singers\", \"dancers\", \"actors\", \"actresses\", \"painters\", \"sculptors\",\n",
    "    \"writers\", \"poets\", \"novelists\", \"journalists\", \"broadcasters\", \"reporters\",\n",
    "    \"photographers\", \"videographers\", \"models\", \"stylists\", \"illustrators\", \"animators\",\n",
    "    \"composers\", \"orchestrators\", \"producers\", \"performers\", \"entertainers\", \"storytellers\",\n",
    "    \"comedians\", \"magicians\", \"acrobats\", \"improvisers\", \"mimes\", \"puppeteers\",\n",
    "    \n",
    "    # Trades and Manual Labor\n",
    "    \"carpenters\", \"electricians\", \"plumbers\", \"mechanics\", \"drivers\", \"pilots\", \"sailors\",\n",
    "    \"chefs\", \"bakers\", \"butchers\", \"tailors\", \"seamstresses\", \"dressmakers\", \"gardeners\",\n",
    "    \"farmers\", \"fishers\", \"hunters\", \"blacksmiths\", \"welders\", \"masons\", \"bricklayers\",\n",
    "    \"roofers\", \"installers\", \"packers\", \"movers\", \"cleaners\", \"laborers\", \"technicians\",\n",
    "    \"operators\", \"cashiers\", \"clerks\", \"servicemen\", \"waiters\", \"waitresses\", \"bartenders\",\n",
    "    \"baristas\", \"cheerleaders\",\n",
    "    \n",
    "    # Sports and Recreation\n",
    "    \"athletes\", \"runners\", \"swimmers\", \"cyclists\", \"skaters\", \"golfers\", \"tennis players\",\n",
    "    \"footballers\", \"basketball players\", \"baseball players\", \"hockey players\", \"boxers\",\n",
    "    \"wrestlers\", \"martial artists\", \"soccer players\", \"cricketers\", \"fencers\", \"surfers\",\n",
    "    \"skiers\", \"snowboarders\", \"rowers\", \"kayakers\", \"climbers\", \"fishermen\",\n",
    "    \n",
    "    # Miscellaneous and Other Groups\n",
    "    \"volunteers\", \"activists\", \"campaigners\", \"participants\", \"contributors\",\n",
    "    \"collaborators\", \"organizers\", \"innovators\", \"thinkers\", \"visionaries\", \"pioneers\",\n",
    "    \"trendsetters\", \"enthusiasts\", \"collectors\", \"critics\", \"reviewers\", \"bloggers\",\n",
    "    \"vloggers\", \"podcasters\", \"gamers\", \"streamers\", \"followers\", \"subscribers\",\n",
    "    \"examiners\", \"observers\", \"spectators\", \"bystanders\", \"residents\", \"citizens\",\n",
    "    \"inhabitants\", \"locals\", \"immigrants\", \"refugees\", \"delegates\", \"evangelists\",\n",
    "    \"architects\", \"adventurers\", \"explorers\", \"pilgrims\", \"campers\", \"travelers\",\n",
    "    \"tourists\", \"visitors\", \"commuters\", \"shoppers\", \"vendors\", \"merchants\",\n",
    "    \"distributors\", \"consumers\", \"farmhands\", \"contractors\", \"freelancers\", \"interns\",\n",
    "    \"apprentices\", \"trainees\", \"seniors\", \"elders\", \"youths\", \"teens\", \"children\",\n",
    "    \"infants\", \"adults\", \"men\", \"women\", \"couples\", \"siblings\", \"parents\", \"grandparents\",\n",
    "    \"cousins\", \"relatives\", \"classmates\", \"roommates\", \"colleagues\", \"associates\",\n",
    "    \"partners\", \"comrades\", \"confederates\", \"allies\", \"supporters\", \"backers\", \"fans\",\n",
    "    \"members\", \"cadets\", \"rookies\", \"veterans\", \"champions\", \"contenders\", \"finalists\",\n",
    "    \"competitors\", \"medalists\", \"record-holders\", \"brainiacs\", \"geeks\", \"nerds\",\n",
    "    \"whizzes\", \"techies\", \"creatives\", \"ideators\", \"facilitators\", \"moderators\",\n",
    "    \"supervisors\", \"evaluators\", \"assessors\"\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2689e13a",
   "metadata": {},
   "outputs": [],
   "source": [
    "result_dirs = ['open-images/result_csv', 'coco/result_csv']\n",
    "final_dir = '../results'\n",
    "captions = pd.DataFrame(columns=['image_id', 'caption', 'dataset'])\n",
    "for dir in result_dirs:\n",
    "    for csv in os.listdir(os.path.join(dataset_dir, dir)):\n",
    "        if 'captions' not in csv:\n",
    "            continue\n",
    "        df = pd.read_csv(os.path.join(os.path.join(dataset_dir, dir), csv))\n",
    "        captions = pd.concat([captions, df])\n",
    "filtered = pd.DataFrame(columns=['image_id', 'caption', 'dataset'])\n",
    "# check if caption contains single\n",
    "for i, keyword in enumerate(person_plural_words):\n",
    "    print(f'filtering for word {i}/{len(person_plural_words)}')\n",
    "    filtered = pd.concat([filtered, captions[(captions['caption'].str.contains(f\"\\\\b{keyword}\\\\b\", case=False))]])\n",
    "    \n",
    "filtered = filtered[~filtered['caption'].str.contains('two')]\n",
    "filtered = filtered[~filtered['caption'].str.contains('Two')]\n",
    "filtered = filtered[~filtered['caption'].str.contains('TWO')]\n",
    "filtered = filtered[~filtered['caption'].str.contains('three')]\n",
    "filtered = filtered[~filtered['caption'].str.contains('Three')]\n",
    "filtered = filtered[~filtered['caption'].str.contains('THREE')]\n",
    "\n",
    "\n",
    "for word in ['women', 'Women', 'WOMEN', 'WOMAN', 'Woman', 'woman', 'man', 'MAN', 'Man', 'men', 'Men', 'MEN']:\n",
    "    filtered['caption'] = filtered['caption'].apply(lambda x: re.sub(f\"\\\\b{word}\\\\b\", 'person' if 'a' in word else 'persons', x))\n",
    "\n",
    "\n",
    "print(filtered)\n",
    "filtered.to_csv(os.path.join(final_dir, \"filtered_captions.csv\"), index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b616defe",
   "metadata": {},
   "outputs": [],
   "source": [
    "final_csv_path = '../results/filtered_captions.csv'\n",
    "sample_dir = '../results/batches'\n",
    "df = pd.read_csv(final_csv_path)\n",
    "num_sample = 10\n",
    "total = 8000\n",
    "num_needed_samples = total / num_sample\n",
    "for i in range(int(num_needed_samples)):\n",
    "    sample = df.sample(n=num_sample)\n",
    "\n",
    "    # print(sample)\n",
    "    sample.to_csv(os.path.join(sample_dir, f'{i}.csv'), index=False)\n",
    "    df = df.drop(sample.index)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
